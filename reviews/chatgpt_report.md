Understood. Also: **some of the files you uploaded earlier expired on my side**, so I can‚Äôt reference their exact code paths right now. But you *did* paste the runtime logs, and that‚Äôs enough to write a clean `.md` you can hand to Claude to ‚Äúget it ready‚Äù + add the missing logs.

Here‚Äôs a **single `.md` file** (copy/paste as-is):

```md
# SqlQueryBuddy ‚Äì Hugging Face Readiness + Logging Upgrade (NO SQL changes)
Date: 2026-02-15

## Objective
Make the Space production-ready for judging/testing by:
1) Improving runtime observability (logs + UI status).
2) Making configuration explicit and safe (Hugging Face Variables/Secrets).
3) Making OpenAI failures self-explanatory (quota/rate-limit/auth/model).
4) Preventing ‚Äúsilent fallback‚Äù confusion (always show mode/provider in UI).

Important: Do NOT change SQL generation logic or prompts in this task.

---

## Current problem (from logs)
Runtime logs show:
- "OpenAI rate limit exceeded - will use local fallback"
- "LLM insights failed ... falling back to local generator"
- "RateLimitError: 429 ... code: insufficient_quota"

Interpretation:
- This is NOT a true per-minute ‚Äúrate limit‚Äù. The OpenAI response indicates `insufficient_quota` (billing/credit issue).
- The app currently logs too little context: no model name, no provider mode, no request id, no config state, and the message text is misleading (‚Äúrate limit exceeded‚Äù).

---

## 1) Add a clear ‚ÄúAI Status‚Äù indicator in the UI (always visible)
Add a header badge that shows:

### When OpenAI is active
‚úÖ **OpenAI Connected**  
- Model: `<OPENAI_MODEL>`  
- Provider: OpenAI  
- Mode: `openai`

### When fallback is active
üü° **Fallback Mode (Local Insights)**  
- Reason: `insufficient_quota` / `invalid_api_key` / `rate_limited` / `timeout` / `network_error`  
- Last error timestamp

### When misconfigured
üî¥ **Misconfigured**
- Missing `OPENAI_API_KEY` (if required)
- Invalid `OPENAI_MODEL`

Also add a small ‚ÄúDetails‚Äù expand section that shows:
- provider/mode
- model
- temperature
- timeout
- insights enabled?
- masked key present? (true/false)
- last error code + message snippet (no secrets)

---

## 2) Improve logging (more useful, minimal noise)
### 2.1 Log configuration summary at startup (safe)
At startup log **one line**:
- mode/provider
- model
- temperature
- timeout
- insights enabled
- OPENAI_API_KEY present? true/false (never print key)

Example:
`Startup config: mode=auto provider=openai model=gpt-4o-mini insights=true timeout=60 key_present=true`

### 2.2 Log every LLM call outcome with structured fields
On each insights generation attempt, log:
- model
- provider
- duration_ms
- outcome: success/fallback
- error_type + error_code if error
- correlation_id (UUID per request)

Example on failure:
`LLM call failed: req_id=... provider=openai model=gpt-4o-mini duration_ms=842 error_code=insufficient_quota http=429 -> fallback=local`

### 2.3 Fix misleading message text
If OpenAI returns:
- 429 + `insufficient_quota` ‚Üí log: **OpenAI quota/billing exceeded**
- 429 + `rate_limit_exceeded` ‚Üí log: **OpenAI rate limited**
- 401 ‚Üí log: **OpenAI invalid API key**
- 404 ‚Üí log: **model_not_found**
- timeout ‚Üí log: **timeout**
- network errors ‚Üí log: **network**

Do not call everything ‚Äúrate limit exceeded‚Äù.

### 2.4 Capture the full exception safely
Store:
- exception class
- error.code (if present)
- http_status (if present)
- message (truncate to 200 chars)
Never store secrets, headers, or full stack traces in UI.

---

## 3) Add a ‚ÄúTest OpenAI Connection‚Äù button in the UI
Add a button that:
- uses the configured OpenAI client
- makes a minimal request (tiny prompt, low tokens)
- returns success/fail with a helpful message

If it fails, show exact categorized fix:
- `insufficient_quota`: ‚ÄúYour OpenAI account has no active quota/credits. Check Billing in OpenAI platform.‚Äù
- `invalid_api_key`: ‚ÄúKey is invalid or revoked.‚Äù
- `model_not_found`: ‚ÄúModel name not available for this key.‚Äù
- `rate_limit_exceeded`: ‚ÄúToo many requests; wait or lower request frequency.‚Äù
- timeout: ‚ÄúIncrease timeout or check network.‚Äù

---

## 4) Hugging Face configuration contract (Secrets/Variables)
The Space must rely on HF Settings and NOT on committed `.env`.

### Secrets (HF Settings ‚Üí Secrets)
- OPENAI_API_KEY = `sk-...` (required for OpenAI mode)

### Variables (HF Settings ‚Üí Variables)
- OPENAI_MODEL = `gpt-4o-mini` (default if not set)
- APP_MODE = `auto` | `openai` | `local`
  - auto: use OpenAI if key exists else local
  - openai: require OpenAI; if fails, show error (no silent fallback)
  - local: always use local generator (for demos)
- OPENAI_TIMEOUT_SECONDS = `60`
- OPENAI_TEMPERATURE = `0`
- SHOW_DEBUG_PANEL = `true/false`

---

## 5) Behavior rules (no more silent confusion)
### APP_MODE=openai
- If OpenAI fails, do NOT silently switch.
- Show UI error badge with reason + fix.

### APP_MODE=auto
- Fallback is allowed.
- Must display fallback badge and reason clearly.
- Must log the reason with code.

### APP_MODE=local
- Never call OpenAI.
- Show ‚ÄúLocal Mode‚Äù.

---

## 6) Acceptance criteria (what ‚Äúready‚Äù means)
1) UI always shows which mode is active (OpenAI vs Local).
2) Logs always include model + req_id + categorized error code for failures.
3) `insufficient_quota` is correctly labeled (not ‚Äúrate limit exceeded‚Äù).
4) ‚ÄúTest OpenAI Connection‚Äù tells me exactly what is wrong and how to fix it.
5) No secrets ever printed in logs or UI.

---

## 7) Notes on the current error
Your log indicates: `429` with `code=insufficient_quota`.
This typically means:
- billing not enabled, or
- no remaining credits/quota, or
- using a key/org without quota.

Once the app has the ‚ÄúTest OpenAI Connection‚Äù tool + better logs, we can confirm exactly.
```

### What to do after Claude applies this

In Hugging Face Space ‚Üí **Settings**:

* **Secrets**: set `OPENAI_API_KEY`
* **Variables**:

  * `OPENAI_MODEL=gpt-4o-mini`
  * `APP_MODE=openai` (so it won‚Äôt silently fallback while you test)
  * `SHOW_DEBUG_PANEL=true`

Then restart Space and click **Test OpenAI Connection**. 
